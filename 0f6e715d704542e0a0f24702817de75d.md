id: 0f6e715d704542e0a0f24702817de75d
parent_id: 5184b2985ed44275b8958a5fdb84f2b4
item_type: 1
item_id: 989faf8706574a4b8719e7d3764c1473
item_updated_time: 1590490411373
title_diff: 
body_diff: "@@ -2171,20 +2171,19 @@\n ion for \n-that\n+one\n  output \n@@ -2213,16 +2213,17 @@\n  follows\n+:\n %0A$$%0A%5Chat\n@@ -2251,16 +2251,119 @@\n w_i%0A$$%0A%0A\n+And for all connected neurons (aka multi-output perceptron):%0A$$%0A%5Chat%7By%7D_j=%5Csum_%7Bi=1%7D%5E%7Bn%7Dx_iw_%7Bi,j%7D%0A$$%0A%0A\n ## Bias \n@@ -2582,12 +2582,18 @@\n t%7By%7D\n+_j\n =w_\n-0\n+%7B0,j%7D\n +%5Csu\n@@ -2612,29 +2612,22 @@\n _iw_\n-i\n+%7Bi,j%7D\n %0A$$%0A%0A## \n-Non-linear a\n+A\n ctiv\n@@ -2739,103 +2739,315 @@\n tion\n-. The activation function can convert the prediction into something useful to be used later.%0A%0AA\n+ represented as:%0A%0A$$%0Ag%0A$$%0A%0A### Importance of non-linearity%0AActivation functions are non linear because the equation so far produces a linear equation as the prediction. As real life data is not normally linear, a linear model may not effectively predict the output. Thus, a non-linearity in the form of an a\n ctiv\n@@ -3064,81 +3064,160 @@\n tion\n+ i\n s a\n-re non linear because the equation so far produces a linear equation%0A%0A\n+pplied.%0A%0A### Additional utility of activation functions%0AThe activation function can convert the prediction into something useful to be used later. \n A co\n@@ -3364,14 +3364,20 @@\n t%7By%7D\n+_j\n =g(w_\n-0\n+%7B0,j%7D\n +%5Csu\n@@ -3392,17 +3392,21 @@\n %7Bn%7Dx_iw_\n-i\n+%7Bi,j%7D\n )%0A$$%0A%0AOt\n@@ -3448,16 +3448,17 @@\n  include\n+:\n %0A1. Hype\n@@ -3514,12 +3514,16 @@\n elu)%0A%0A%0A%0A%0A%0A%0A%0A\n+%0A%0A%0A%0A\n"
metadata_diff: {"new":{},"deleted":[]}
encryption_cipher_text: 
encryption_applied: 0
updated_time: 2020-05-26T10:54:44.837Z
created_time: 2020-05-26T10:54:44.837Z
type_: 13