Linear Algebra

# MIT 18.06 Linear Algebra
Produced by MIT OpenCourseWare
Taught by W. Gilbert Strang

# Lecture 1: The geometry of linear equations
28/05/2020 20:02

## Representing a system of equations in matrix form
Considering 2 equations and 2 unknown variables $x$ and $y$:
$$
2x-y=0
$$
$$
-x+2y=3
$$

The equations can be represented in matrix form:
$$
Ax=b
$$
$$
\begin{bmatrix}
2&-1\\
-1&2
\end{bmatrix}
\begin{bmatrix}
x\\y
\end{bmatrix}
=
\begin{bmatrix}
0\\3
\end{bmatrix}
$$

## Linear combination of vectors
Linear algebra follows linear operations. The following 2 rules always apply:

Rule 1: Vector addition
$$
\begin{bmatrix}
2\\-1
\end{bmatrix}
+
\begin{bmatrix}
-1\\2
\end{bmatrix}
=
\begin{bmatrix}
1\\1
\end{bmatrix}
$$


Rule 2: Scalar multiplication
$$
x
\begin{bmatrix}
2\\-1
\end{bmatrix}
=
\begin{bmatrix}
2x\\-x
\end{bmatrix}
$$

## Column view
The linear combination can be represented through "columns" or individual vectors by using the coefficients:
$$
x
\begin{bmatrix}
2\\-1
\end{bmatrix}
+y
\begin{bmatrix}
-1\\2
\end{bmatrix}
=
\begin{bmatrix}
0\\3
\end{bmatrix}
$$
By eye, the column view can help solve that $x=1$ and $y=2$ solves this system of equations.

## 3 dimensional matrix
Consider the following linear combination:
$$
Ax=b
$$
$$
\begin{bmatrix}
2&-1&0\\
-1&2&-1\\
0&-3&4
\end{bmatrix}
\begin{bmatrix}
x\\y\\z
\end{bmatrix}
=
\begin{bmatrix}
0\\-1\\4
\end{bmatrix}
$$
The corresponding column view:
$$
x
\begin{bmatrix}
2\\-1\\0
\end{bmatrix}
+y
\begin{bmatrix}
-1\\2\\-1
\end{bmatrix}
+z
\begin{bmatrix}
0\\-1\\4
\end{bmatrix}
=
\begin{bmatrix}
0\\-1\\4
\end{bmatrix}
$$
By eye, the column view can help solve that $x=0$, $y=0$ and $z=1$

## Is it possible to solve $Ax=b$ for every value of $b$?
Normally, yes.

However, there are special cases where it is not possible. Lets suppose the following 3-D matrix represented in column view:
$$
x
\begin{bmatrix}
2\\-1\\0
\end{bmatrix}
+y
\begin{bmatrix}
0\\-1\\4
\end{bmatrix}
+z
\begin{bmatrix}
0\\-1\\4
\end{bmatrix}
=
b
$$
Since vectors $y$ and $z$ are on the same plane, there is no linear combination that will result in $b$ except for solutions that lie in the same plane as $x$.

## Multiplying matrix $A$ with vector $x$

Consider linear combination:
$$
Ax=b
$$
$$
\begin{bmatrix}
2&5&3\\
1&3&4\\
1&2&3
\end{bmatrix}
\begin{bmatrix}
1\\2\\3
\end{bmatrix}
=
b
$$
Re-written in column view:
$$
1
\begin{bmatrix}
2\\1\\1
\end{bmatrix}
+2
\begin{bmatrix}
5\\3\\2
\end{bmatrix}
+3
\begin{bmatrix}
3\\4\\3
\end{bmatrix}
=
\begin{bmatrix}
21\\19\\14
\end{bmatrix}
$$

General form:
$$
Ax=b
$$
$$
\begin{bmatrix}
A_{1,1}&A_{1,2}&A_{1,3}\\
A_{2,1}&A_{2,2}&A_{2,3}\\
A_{3,1}&A_{3,2}&A_{3,3}\\
\end{bmatrix}
\begin{bmatrix}
x_1\\x_2\\x_3
\end{bmatrix}
=
b
$$
Re-written in column view:
$$
x_1
\begin{bmatrix}
A_{1,1}\\A_{2,1}\\A_{3,1}
\end{bmatrix}
+x_2
\begin{bmatrix}
A_{1,2}\\A_{2,2}\\A_{3,2}
\end{bmatrix}
+x_3
\begin{bmatrix}
A_{1,3}\\A_{2,3}\\A_{3,3}
\end{bmatrix}
=
\begin{bmatrix}
x_1A_{1,1}+x_2A_{1,2}+x_3A_{1,3}\\
x_1A_{2,1}+x_2A_{2,2}+x_3A_{2,3}\\
x_1A_{3,1}+x_2A_{3,2}+x_3A_{3,3}\\
\end{bmatrix}
$$
Rule: Matrix $A$ multiplied with column $x$ will result in a column $b$.



# Lecture 2: Elimination
28/05/2020 22:47
29/05/2020 11:28

Elimination is used to solve a system of equations.

Consider a system of equations:
$$
x+2y+z=2
$$
$$
3x+8y+z=12
$$
$$
4y+z=2
$$

Represented in matrix form:
$$Ax=b$$
$$
\begin{bmatrix}
1&2&1\\
3&8&1\\
0&4&1
\end{bmatrix}
\begin{bmatrix}
x\\
y\\
z
\end{bmatrix}
=
\begin{bmatrix}
2\\
12\\
2
\end{bmatrix}
$$

## Augmented matrix $\tilde{A}$
An augmented matrix combines $A$ and $b$ since operations will be performed on both.

$$
\tilde{A}= 
\begin{bmatrix}
1&2&1&&2\\
3&8&1&&12\\
0&4&1&&2
\end{bmatrix}
$$

## Gaussian elimination

### Elementary row operations
2 manipulations can be used to eliminate unknowns:
1. Swapping rows
2. Subtracting a multiple of the row above from row below

### Identifying pivot points
Pivot points are found in positions $A_{1,1}$, $A_{2,2}$, $A_{3,3}$,...
$$
\begin{bmatrix}
\boxed{1}&2&1&&2\\
3&\boxed{8}&1&&12\\
0&4&\boxed{1}&&2
\end{bmatrix}
$$
The numbers in pivot points cannot be 0. If they are,
1. Elementary row operation (1): Swap with appropriate row below.
2. Gaussian elimination fails.

### Eliminating $A_{2,1}$
Pivot is 1.
$$
\begin{bmatrix}
\boxed{1}&2&1&&2\\
3&8&1&&12\\
0&4&1&&2
\end{bmatrix}
$$

Using elementary row operation (2), 

Multiplying the pivot by 3 and subtracting it from row 2 will eliminate $A_{2,1}$.

Resultant matrix:
$$
\begin{bmatrix}
1&2&1&&2\\
0&2&-2&&6\\
0&4&1&&2
\end{bmatrix}
$$

### Eliminating $A_{3,1}$
As $A_{3,1}=0$, it is already eliminated.

### Eliminating $A_{3,2}$ and thus calculating upper triangular matrix $U$
Pivot is 2.
$$
\begin{bmatrix}
1&2&1&&2\\
0&\boxed{2}&-2&&6\\
0&4&1&&2
\end{bmatrix}
$$

Using elementary row operation (2),

Multiplying the pivot by 2 and subtracting from row 3 will eliminate $A_{3,2}$

Resultant matrix:
$$
U=
\begin{bmatrix}
1&2&1&&2\\
0&2&-2&&6\\
0&0&5&&-10
\end{bmatrix}
$$

Computers typically reduce matrix $A$ until it resembles upper triangular matrix $U$. This is also known as row echelon form (not to be confused with row-reduced echelon form).

## Back substitution
Back substitution starts with the 'bottom' of the matrix, since there is only 1 unknown and works up the matrix eventually solving the system of equations.

Matrix $U$ represented as a system of equations:

$$
x+2y+z=2
$$
$$
2y-2z=6
$$
$$
5z=-10
$$

Solved:
$$z=-2$$
$$y=1$$
$$x=2$$

## Elimination matrices $E$
Elimination matrices show the matrices that need to be multiplied to convert $A$ to $U$.

### Tip: Row multiplication
Consider:
$$
\begin{bmatrix}
1&2&3
\end{bmatrix}
\begin{bmatrix}
2&5&3\\
1&3&4\\
1&2&3
\end{bmatrix}
=
b
$$
Re-written in row view:
$$
1
\begin{bmatrix}
2&5&3\\
\end{bmatrix}
+2
\begin{bmatrix}
1&3&4\\
\end{bmatrix}
+3
\begin{bmatrix}
1&2&3\\
\end{bmatrix}
=
\begin{bmatrix}
10&16&18
\end{bmatrix}
$$

1. Any row operation happens on the left of the matrix.
2. Any column operation happens on the right of the matrix.

### Tip: Identity matrix $I$
We start with identity matrix $I$:
$$
I=
\begin{bmatrix}
1&0&0\\
0&1&0\\
0&0&1
\end{bmatrix}
$$

A special property of $I$ is that any matrix $A$ multiplied by $I$ will remain as $A$:
$$
IA=A
$$
$$
\begin{bmatrix}
1&0&0\\
0&1&0\\
0&0&1
\end{bmatrix}
\begin{bmatrix}
2&5&3\\
1&3&4\\
1&2&3
\end{bmatrix}
=
\begin{bmatrix}
2&5&3\\
1&3&4\\
1&2&3
\end{bmatrix}
$$

### Step 1: Calculating $E_{2,1}$
Since only row operations were used, $E_{2,1}$ will be multiplied to the left of $A$

It can be said that:
$$
E_{2,1}
\begin{bmatrix}
1&2&1\\
3&8&1\\
0&4&1
\end{bmatrix}
=
\begin{bmatrix}
1&2&1\\
0&2&-2\\
0&4&1
\end{bmatrix}
$$

$E_{2,1}$ is a manipulation of $I$. The 1st and 3rd rows remain unchanged, so $E_{2,1}$ mirrors the 1st the 3rd row of $I$.

Row 2 
* Multiplies row 1 by -3,
* Adds it to row 2. Thus:

$$
\begin{bmatrix}
1&0&0\\
-3&1&0\\
0&0&1
\end{bmatrix}
\begin{bmatrix}
1&2&1\\
3&8&1\\
0&4&1
\end{bmatrix}
=
\begin{bmatrix}
1&2&1\\
0&2&-2\\
0&4&1
\end{bmatrix}
$$

### Step 2: Calculating $E_{3,2}$
It can be said that:
$$
E_{3,2}
\begin{bmatrix}
1&2&1\\
0&2&-2\\
0&4&1
\end{bmatrix}
=
\begin{bmatrix}
1&2&1\\
0&2&-2\\
0&0&5
\end{bmatrix}
$$

$E_{3,2}$ is also a manipulation of $I$. The 1st and 2nd rows remain unchanged, so $E_{3,2}$ mirrors the 1st the 2rd row of $I$.

Row 3
* Multiplies row 2 by -2,
* Adds it to row 3. Thus:

$$
\begin{bmatrix}
1&0&0\\
0&1&0\\
0&-2&1
\end{bmatrix}
\begin{bmatrix}
1&2&1\\
0&2&-2\\
0&4&1
\end{bmatrix}
=
\begin{bmatrix}
1&2&1\\
0&2&-2\\
0&0&5
\end{bmatrix}
$$

### Step 3: Representing as one equation
Putting it all together:
$$
\begin{bmatrix}
1&0&0\\
0&1&0\\
0&-2&1
\end{bmatrix}
\left(
\begin{bmatrix}
1&0&0\\
-3&1&0\\
0&0&1
\end{bmatrix}
\begin{bmatrix}
1&2&1\\
3&8&1\\
0&4&1
\end{bmatrix}
\right)
=
\begin{bmatrix}
1&2&1\\
0&2&-2\\
0&0&5
\end{bmatrix}
$$
More simply put:
$$
E_{3,2}(E_{2,1}A)=U
$$
Using the *associative property*, equation can be re-written:
$$(E_{3,2}E_{2,1})A=U$$

## Permutation matrix $P$
Elementary row operation (1) of swapping rows can be done using a permutation matrix $P$. 

The following permutation matrix swaps row 1 and 3 by
1. Multiplying row 1 by 0, then multiplying row 3 by 1 and adding it to row 1.
2. Multiplying row 1 by 1, then multiplying row 3 by 0 and adding it to row 3.
$$
P=
\begin{bmatrix}
0&0&1\\
0&1&0\\
1&0&0
\end{bmatrix}
$$

Similarly, the following permutation matrix swaps rows 2 and 3:
$$
P=
\begin{bmatrix}
1&0&0\\
0&0&1\\
0&1&0
\end{bmatrix}
$$

### Number of permutations
* A 2x2 matrix has 2 permutation matrices
	* Identity
	* Swap row 1 and 2
* A 3x3 matrix has 6 permutation matrices
	* Identity
	* Swap row 1 and 2
	* Swap row 1 and 3
	* Swap row 2 and 3
	* Swap row 1 and 2 and Swap row 2 and 3
	* Swap row 1 and 3 and Swap row 2 and 3
* A 4x4 matrix has $4!=24$ permutation matrices
* ...

# Lecture 3: Matrix inversion
31/05/2020 18:51

## Matrix inversion identity
Matrix $A$ is invertible if:
$$
A^{-1}A=I=AA^{-1}
$$

## Test for invertibility
If there is a vector $x$ $(x\not=0)$ that satisfies:
$$
Ax=0
$$
then $A$ is not invertible. 

For example, take matrix $A$:
$$
\begin{bmatrix}
1&3\\
2&6
\end{bmatrix}
$$
There is a vector $x$:
$$
\begin{bmatrix}
3\\
-1
\end{bmatrix}
$$
Such that $Ax=0$. Thus, $A$ is non-invertible.
$$
\begin{bmatrix}
1&3\\
2&6
\end{bmatrix}
\begin{bmatrix}
3\\
-1
\end{bmatrix}
=
\begin{bmatrix}
0\\
0
\end{bmatrix}
$$
## Matrix inversion using Gauss-Jordan elimination
Let $A$ be an invertible matrix:
$$
AA^{-1}=I
$$
$$
\begin{bmatrix}
1&3\\
2&7
\end{bmatrix}A^{-1}
=
\begin{bmatrix}
1&0\\
0&1
\end{bmatrix}
$$
### Step 1: Create an augmented matrix by combining $A$ and $I$:
$$
\begin{bmatrix}
1&3&&1&0\\
2&7&&0&1
\end{bmatrix}
$$

### Step 2: Gaussian elimination of $A_{2,1}$
Multiply row 1 by 2 and subtract from row 2:
$$
\begin{bmatrix}
1&3&&1&0\\
0&1&&-2&1
\end{bmatrix}
$$

### Step 3: Jordan elimination of $A_{1,2}$
Multiply row 2 by 3 and subtract from row 1:
$$
\begin{bmatrix}
1&0&&7&-3\\
0&1&&-2&1
\end{bmatrix}
$$	
$$
A^{-1}=
\begin{bmatrix}
7&-3\\
-2&1
\end{bmatrix}
$$
Because $EA=I$, so $E$ must be $A^{-1}$.

## Rules of inverses

### Inverse of a matrix product
$$
(AB)^{-1}=B^{-1}A^{-1}
$$


# Lecture 4: LU Decomposition
07/06/2020 16:19

For computers, decomposing $A$ into a product of a lower triangular matrix $L$ and and upper triangular matrix $U$ is beneficial.

## LU decomposition for 2x2 matrix
Let matrix $A$ be defined as:
$$
A=
\begin{bmatrix}
2&1\\
8&7
\end{bmatrix}
$$
Calculating elimination matrix $E_{2,1}$:
$$
E_{2,1}A=U
$$
$$
\begin{bmatrix}
1&0\\
-4&1
\end{bmatrix}
\begin{bmatrix}
2&1\\
8&7
\end{bmatrix}
=
\begin{bmatrix}
2&1\\
0&3
\end{bmatrix}
$$

Multiplying both sides by $E_{2,1}^{-1}$
$$
E_{2,1}^{-1}E_{2,1}A=E_{2,1}^{-1}U
$$
Recall identity of inverse matrix $AA^{-1}=A^{-1}A=I$
$$
A=E_{2,1}^{-1}U
$$
Since $E_{2,1}^{-1}$ is a lower triangular matrix, it can be re-written as $L$. Thus:
$$
A=LU
$$

## LU decomposition for a 3x3 matrix
Calculating all 3 elimination matrices for $A$:
$$
E_{3,2}E_{3,1}E_{2,1}A=U
$$
Recall inverse of matrix product $(AB)^{-1}=B^{-1}A^{-1}$
$$
E_{2,1}^{-1}E_{3,1}^{-1}E_{3,2}^{-1}E_{3,2}E_{3,1}E_{2,1}A=E_{2,1}^{-1}E_{3,1}^{-1}E_{3,2}^{-1}U
$$
Recall identity of inverse matrix $AA^{-1}=A^{-1}A=I$
$$
A=E_{2,1}^{-1}E_{3,1}^{-1}E_{3,2}^{-1}U
$$
Since $E_{2,1}^{-1}$, $E_{3,1}^{-1}$ and $E_{3,2}^{-1}$ are all lower triangular matrices, they can be multiplied and re-written as $L$ Thus:
$$
A=LU
$$

## LU decomposition that requires row exchanges
Recall that to swap rows, a permutation matrix $P$ is required. Thus, LU decomposition can be re-written as:
$$
PA=LU
$$

# Lecture 5: Matrix transpose
08/06/2020 16:40

Transposing a matrix turns columns into rows and rows into columns

## Matrix transpose $A^T$ (sometimes notated $A'$)
Let matrix $A$ be defined as:
$$
A=
\begin{bmatrix}
1&3\\
2&3\\
4&1
\end{bmatrix}
$$
Then the transpose of $A$ can be calculated:
$$
A^T=
\begin{bmatrix}
1&2&4\\
3&3&1\\
\end{bmatrix}
$$

### General form
$$
A_{i,j}=A_{j,i}^T
$$

## Symmetric matrix
A matrix $A$ is symmetric if:
$$
A=A^T
$$
For example:
$$
A=A^T=
\begin{bmatrix}
3&1&7\\
1&4&6\\
7&6&2
\end{bmatrix}
$$

### Proof that $R^TR$ is symmetric
Let $R$ represent a rectangular matrix:
$$
R=
\begin{bmatrix}
1&3\\
2&3\\
4&1
\end{bmatrix}
$$
$$
R^TR=
\begin{bmatrix}
1&3\\
2&3\\
4&1
\end{bmatrix}
\begin{bmatrix}
1&2&4\\
3&3&1\\
\end{bmatrix}
=
\begin{bmatrix}
10&14&7\\
14&3&11\\
7&11&17
\end{bmatrix}
$$
If $R^TR$ is symmetric, the following must hold true
$$
R^TR=(R^TR)^T
$$
Similar to inverting a product, transposing a product flips the order:
$$
R^TR=R^T(R^T)^T
$$
$$
R^TR=R^TR
$$

## Rules of matrix transpose

### Inverse of a matrix transpose
$$
(A^{-1})^T=(A^T)^{-1}
$$
###

### Inverse of permutation matrix $P$
$$
P^{-1}=P^T
$$
Thus:
$$
P^TP=I
$$





id: 5a82b06aa11e470ca59920afb5102ecd
parent_id: c531fb3a1321454ab0a3a58decb0bf67
created_time: 2020-05-28T11:59:48.750Z
updated_time: 2020-06-08T09:27:17.853Z
is_conflict: 0
latitude: 0.00000000
longitude: 0.00000000
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 0
user_created_time: 2020-05-28T11:59:48.750Z
user_updated_time: 2020-06-08T09:27:17.853Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
type_: 1