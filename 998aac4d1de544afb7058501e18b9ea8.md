id: 998aac4d1de544afb7058501e18b9ea8
parent_id: 0f6e715d704542e0a0f24702817de75d
item_type: 1
item_id: 989faf8706574a4b8719e7d3764c1473
item_updated_time: 1590491083589
title_diff: 
body_diff: "@@ -1207,16 +1207,138 @@\n Output%0A%0A\n+When the multiple perceptrons are combined with each other, they form what is known as an Artifical Neural Network (ANN)%0A%0A\n ## Input\n@@ -2377,11 +2377,59 @@\n $$%0A%0A\n-And\n+Let j represent the number of output neurons. Thus,\n  for\n@@ -3649,16 +3649,16 @@\n  (tanh)%0A\n-\n 2. Recti\n@@ -3682,16 +3682,620 @@\n (relu)%0A%0A\n+### Multi-layered perceptron/Sequential model%0AThese are typically used in deep neural networks where the layers are automatically generated. In standard ANNs, %0A%0ALet k represent the number of layers. The prediction for each layer then becomes%0A%0A$$%0A%5Chat%7By%7D_%7Bj,k%7D=g(w_%7B0,j%7D%5E%7B(k)%7D+%5Csum_%7Bi=1%7D%5E%7Bn%7Dx_iw_%7Bi,j%7D%5E%7B(k)%7D)%0A$$%0A%0A## Loss %0AThe loss tells us how wrong the prediction was. It does this by comparing the prediction to the actual value. %0A%0AThere are mathematical functions that can quantify loss. They are known typically as (but mean the same thing):%0A1. Cost function%0A2. Objective function%0A3. Empirical risk%0A%0A%0A\n %0A%0A%0A%0A%0A%0A%0A%0A\n"
metadata_diff: {"new":{},"deleted":[]}
encryption_cipher_text: 
encryption_applied: 0
updated_time: 2020-05-26T11:04:44.857Z
created_time: 2020-05-26T11:04:44.857Z
type_: 13